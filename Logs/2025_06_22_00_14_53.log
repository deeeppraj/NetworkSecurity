2025-06-22 00:14:57,488 - httpx - INFO - HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
2025-06-22 00:14:57,496 - dagshub - INFO - Accessing as deeeppraj
2025-06-22 00:14:58,053 - httpx - INFO - HTTP Request: GET https://dagshub.com/api/v1/repos/deeeppraj/NetworkSecurity "HTTP/1.1 200 OK"
2025-06-22 00:14:58,669 - httpx - INFO - HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
2025-06-22 00:14:58,674 - dagshub - INFO - Initialized MLflow to track repo "deeeppraj/NetworkSecurity"
2025-06-22 00:14:58,676 - dagshub - INFO - Repository deeeppraj/NetworkSecurity initialized!
2025-06-22 00:14:58,756 - werkzeug - WARNING -  * Debugger is active!
2025-06-22 00:14:58,761 - werkzeug - INFO -  * Debugger PIN: 143-507-764
2025-06-22 00:15:30,002 - werkzeug - INFO - 127.0.0.1 - - [22/Jun/2025 00:15:30] "[33mGET /docs HTTP/1.1[0m" 404 -
2025-06-22 00:15:42,949 - werkzeug - INFO - 127.0.0.1 - - [22/Jun/2025 00:15:42] "GET / HTTP/1.1" 200 -
2025-06-22 00:16:07,204 - root - INFO - initiate data ingestion
2025-06-22 00:16:12,667 - root - INFO - performed train test split
2025-06-22 00:16:12,669 - root - INFO - Exporting train and test .csv
2025-06-22 00:16:12,907 - root - INFO - Created my train test.csv
2025-06-22 00:16:12,908 - root - INFO - data ingestion completed . generated data ingestion artifact ->DataIngestionArtifact(trained_file_path='artifacts\\06_22_2025_00_14_54\\data_ingestion\\ingested\\train.csv', test_file_path='artifacts\\06_22_2025_00_14_54\\data_ingestion\\ingested\\test.csv')
2025-06-22 00:16:12,909 - root - INFO - starting data validation
2025-06-22 00:16:13,122 - root - INFO - required no. of columns 2
2025-06-22 00:16:13,122 - root - INFO - data frame has no. of columns 31
2025-06-22 00:16:13,123 - root - INFO - required no. of columns 2
2025-06-22 00:16:13,123 - root - INFO - data frame has no. of columns 31
2025-06-22 00:16:13,639 - root - INFO - completed with DataValidationArtifact(validation_status=False, validated_train_file_path='artifacts\\06_22_2025_00_14_54\\data_ingestion\\ingested\\train.csv', validated_test_file_path='artifacts\\06_22_2025_00_14_54\\data_ingestion\\ingested\\test.csv', invalid_train_file_path=None, invalid_test_file_path=None, drift_report_file_path='artifacts\\06_22_2025_00_14_54\\data_validation\\drift_report\\report.yaml')
2025-06-22 00:16:13,639 - root - INFO - Initiating my data transformation processs
2025-06-22 00:16:13,640 - root - INFO - starting.....
2025-06-22 00:16:13,695 - root - INFO - read my train and test data as pandas dataframe
2025-06-22 00:16:13,701 - root - INFO - Entered to get null values
2025-06-22 00:16:13,701 - root - INFO - created my imputer pipeline with values as {'missing_values': nan, 'n_neighbors': 3, 'weights': 'uniform'}
2025-06-22 00:16:13,742 - root - INFO - saving my pikle file
2025-06-22 00:16:13,750 - root - INFO - pikle file saved
2025-06-22 00:16:13,751 - root - INFO - saving my pikle file
2025-06-22 00:16:13,759 - root - INFO - pikle file saved
2025-06-22 00:16:13,760 - root - INFO - saved my numpy array and my preprocessor.pkl file
2025-06-22 00:16:13,762 - root - INFO - completed data transformation DataTransformartifact(transformed_obj_file_path='artifacts\\06_22_2025_00_14_54\\data_transformation\\transformed_object\\preprocessing.pkl', transformed_train_file_path='artifacts\\06_22_2025_00_14_54\\data_transformation\\transformed\\train.npy', transformed_test_file_path='artifacts\\06_22_2025_00_14_54\\data_transformation\\transformed\\test.npy')
2025-06-22 00:16:57,262 - root - INFO - saving object in utils file
2025-06-22 00:16:57,288 - root - INFO - saving object in utils file
2025-06-22 00:16:57,321 - root - INFO - model trainer artifact ModelTrainerArtifact(trained_model_file_path='artifacts\\06_22_2025_00_14_54\\model_trainer\\trained_model\\model.pkl', trained_metric_artifact=ClassificationArtifact(f1_score=0.9915452785983498, precission_score=0.990233977619532, recall_score=0.9928600571195431), test_metric_artifact=ClassificationArtifact(f1_score=0.9715415019762846, precission_score=0.9639215686274509, recall_score=0.9792828685258964))
2025-06-22 00:16:57,325 - root - INFO - completed model training ModelTrainerArtifact(trained_model_file_path='artifacts\\06_22_2025_00_14_54\\model_trainer\\trained_model\\model.pkl', trained_metric_artifact=ClassificationArtifact(f1_score=0.9915452785983498, precission_score=0.990233977619532, recall_score=0.9928600571195431), test_metric_artifact=ClassificationArtifact(f1_score=0.9715415019762846, precission_score=0.9639215686274509, recall_score=0.9792828685258964))
2025-06-22 00:16:57,326 - werkzeug - INFO - 127.0.0.1 - - [22/Jun/2025 00:16:57] "GET /train HTTP/1.1" 200 -
2025-06-22 00:20:18,985 - werkzeug - INFO - 127.0.0.1 - - [22/Jun/2025 00:20:18] "GET / HTTP/1.1" 200 -
2025-06-22 00:20:25,199 - werkzeug - INFO - 127.0.0.1 - - [22/Jun/2025 00:20:25] "[31m[1mGET /predict HTTP/1.1[0m" 405 -
2025-06-22 00:20:50,820 - werkzeug - INFO - 127.0.0.1 - - [22/Jun/2025 00:20:50] "GET / HTTP/1.1" 200 -
2025-06-22 00:20:54,749 - werkzeug - INFO - 127.0.0.1 - - [22/Jun/2025 00:20:54] "GET /upload HTTP/1.1" 200 -
2025-06-22 00:21:24,815 - werkzeug - INFO - 127.0.0.1 - - [22/Jun/2025 00:21:24] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
2025-06-22 00:21:24,997 - werkzeug - INFO - 127.0.0.1 - - [22/Jun/2025 00:21:24] "GET /predict?__debugger__=yes&cmd=resource&f=debugger.js HTTP/1.1" 200 -
2025-06-22 00:21:24,999 - werkzeug - INFO - 127.0.0.1 - - [22/Jun/2025 00:21:24] "GET /predict?__debugger__=yes&cmd=resource&f=style.css HTTP/1.1" 200 -
2025-06-22 00:21:25,089 - werkzeug - INFO - 127.0.0.1 - - [22/Jun/2025 00:21:25] "GET /predict?__debugger__=yes&cmd=resource&f=console.png&s=1UwOI2JdD9VoudENYqPY HTTP/1.1" 200 -
2025-06-22 00:21:25,106 - werkzeug - INFO - 127.0.0.1 - - [22/Jun/2025 00:21:25] "GET /predict?__debugger__=yes&cmd=resource&f=console.png HTTP/1.1" 200 -
2025-06-22 00:21:45,875 - werkzeug - INFO -  * Detected change in 'C:\\Users\\Deepraj\\Desktop\\Projects\\NetworkSecurity\\app.py', reloading
